{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ea2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pickle\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.WARNING,  # set 3rd party logs to warning (for hiding it)\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0d3a9",
   "metadata": {},
   "source": [
    "# 1. Define Variables and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d392f3",
   "metadata": {},
   "source": [
    "## 1.1 Train Model Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68b71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details_django = {\n",
    "    'isolation_forest': [],\n",
    "    'local_outilier': [],\n",
    "    'elliptic_envelope': [],\n",
    "}\n",
    "\n",
    "model_details_nginx = {\n",
    "    'isolation_forest': [],\n",
    "    'local_outilier': [],\n",
    "    'elliptic_envelope': [],\n",
    "}\n",
    "\n",
    "model_details_hash = {\n",
    "    'isolation_forest': [],\n",
    "    'local_outilier': [],\n",
    "    'elliptic_envelope': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38520f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'elliptic_envelope',\n",
    "    'isolation_forest', \n",
    "    'local_outilier'\n",
    "]\n",
    "\n",
    "model_classes = {\n",
    "    'isolation_forest': IsolationForest,\n",
    "    'local_outilier': LocalOutlierFactor,\n",
    "    'elliptic_envelope': EllipticEnvelope,\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'isolation_forest': {\n",
    "        'contamination': np.linspace(0.01, 0.5, num=10),         \n",
    "    },\n",
    "    'local_outilier': {\n",
    "        'n_neighbors': np.linspace(1, 200, num=5, dtype='int'),\n",
    "        'novelty': [True]\n",
    "    },\n",
    "    'elliptic_envelope': {\n",
    "        'contamination': np.linspace(0.01, 0.5, num=3),  \n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1c5e8",
   "metadata": {},
   "source": [
    "## 1.2 Define Train Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98bf5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric(y_true, y_pred):\n",
    "    confusion_matrix_data = confusion_matrix(y_true, y_pred) # tn, fp, fn, tp\n",
    "    TN, FP, FN, TP = confusion_matrix_data.ravel()\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    specificity = TN/ (TN + FP)\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        F1 = 'devide by zero'\n",
    "    else:\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "        F1 = f'{F1:.4f}'\n",
    "        \n",
    "    result = {\n",
    "        'confusion_matrix': confusion_matrix_data,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TP': TP,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'specificity': specificity,\n",
    "        'accuracy': accuracy,\n",
    "        'F1': F1,        \n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b95e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_result(model_name, df_train, df_test, select_column):\n",
    "    logger.info(f\"{model_name}\") #print(f\"{model_name}\")                \n",
    "    model_detail = [] \n",
    "    keys = list(parameters[model_name].keys())\n",
    "    values = parameters[model_name].values()\n",
    "    all_combinations = list(itertools.product(*values))\n",
    "    for parameter_value in all_combinations:\n",
    "        parameter_result = {}\n",
    "        for i_parameter in range(len(parameter_value)):\n",
    "            parameter_result[keys[i_parameter]] = parameter_value[i_parameter]\n",
    "\n",
    "        logger.info(f'           parameter_result {parameter_result}')    \n",
    "        model =  model_classes[model_name](**parameter_result)   \n",
    "        model.fit(df_train[select_column].values)\n",
    "        predict_result = model.predict(df_test[select_column].values)\n",
    "        test_set_tmp = df_test.copy(deep=True)\n",
    "        test_set_tmp['predict'] = pd.Series(predict_result).apply(lambda x: 1 if (x == -1) else 0 )        \n",
    "\n",
    "        y_true = test_set_tmp['abnormal']\n",
    "        y_pred = test_set_tmp['predict']\n",
    "        metric_result = calculate_metric(y_true, y_pred)\n",
    "\n",
    "        result = {\n",
    "            \"parameter\": parameter_result,\n",
    "            \"metric_result\": metric_result,\n",
    "            \"predict\": test_set_tmp,\n",
    "#             \"model\": model,    # uncomment this line to save trained model in pickle\n",
    "        }\n",
    "\n",
    "        model_detail.append(result)\n",
    "    return model_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8c1ef",
   "metadata": {},
   "source": [
    "## 1.3 Define Prepare Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1028f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_word = ['404', 'not found', 'internal server error', 'error', 'timed out'] \n",
    "\n",
    "def count_error_word(df, error_word):\n",
    "    for item in error_word:\n",
    "        df[item] = df['log'].str.contains(item).astype(int)\n",
    "    return df\n",
    "\n",
    "def set_train_data(df, error_word):\n",
    "    for item in error_word:\n",
    "        df[item] = np.random.choice([0,1,2], df.shape[0], p=[0.7, 0.2, 0.1]) # 0\n",
    "    return df\n",
    "\n",
    "def group_time(df):\n",
    "    df = df[error_word].groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
    "    df.loc[df.sum(axis=1) > 0, 'abnormal'] = 1\n",
    "    df['abnormal'] = df['abnormal'].fillna(0)\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def print_F1(parameter_results):\n",
    "    F1_list = []\n",
    "    for asset_result in parameter_results:\n",
    "        try:\n",
    "            F1 = float(asset_result['metric_result']['F1'])\n",
    "        except Exception as e:\n",
    "            F1 = 0\n",
    "\n",
    "        F1_list.append(F1)\n",
    "    print(f'     F1 max : {max(F1_list)}, F1 of each hyper: {F1_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f61a9",
   "metadata": {},
   "source": [
    "## 1.4 Define Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bef481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(df_data):\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "    fig = plt.figure()\n",
    "    axs = fig.subplots(2, 1)\n",
    "\n",
    "    data = df_data['predict']\n",
    "\n",
    "    predict_normal = data[data['predict'] == 0]\n",
    "    predict_abnormal = data[data['predict'] == 1]\n",
    "    axs[0].set_title(f'Predict', ha='left', va='center',y=0.5,x=1.009)\n",
    "    axs[0].set_ylim([0, 70])\n",
    "    axs[0].plot(predict_normal['datetime'], predict_normal['error'],'b-',label='$predicted as normal')\n",
    "    for item in error_word: \n",
    "        axs[0].plot(predict_abnormal['datetime'], predict_abnormal[item], 'r.', label=f'$predicted as abnormal')\n",
    "    axs[0].legend()\n",
    "\n",
    "    ground_truth_normal = data[data['abnormal'] == 0]\n",
    "    ground_truth_abnormal = data[data['abnormal'] == 1]\n",
    "    axs[1].set_title(f'Ground Truth', ha='left', va='center',y=0.5,x=1.009)\n",
    "    axs[1].set_ylim([0, 70])\n",
    "    axs[1].plot(ground_truth_normal['datetime'], ground_truth_normal['error'],'b-',label='$ground_truth as normal')\n",
    "    for item in error_word: \n",
    "        axs[1].plot(ground_truth_abnormal['datetime'], ground_truth_abnormal[item], '.', label=f'$ground_truth as {item}')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf6fdf",
   "metadata": {},
   "source": [
    "# 2. Bag-of-word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca917b",
   "metadata": {},
   "source": [
    "## 2.1 process django backend logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70cce6",
   "metadata": {},
   "source": [
    "### 2.1.1 parse logs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ecbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data  = open('input/backend.log', 'r')\n",
    "data_list = []\n",
    "last_date = datetime.strptime('09/Aug/2022 23:50:16', '%d/%b/%Y %H:%M:%S')\n",
    "for i, line in enumerate(log_data):\n",
    "    date_str = line[32:52]\n",
    "    try:\n",
    "        datetime_data = datetime.strptime(date_str, '%d/%b/%Y %H:%M:%S')\n",
    "        last_date = datetime_data\n",
    "        log = line[54:]\n",
    "    except Exception as e:\n",
    "        datetime_data = last_date\n",
    "        log = line[31:]\n",
    "\n",
    "    data_list.append({\n",
    "        'datetime': datetime_data, \n",
    "        'log': log,\n",
    "    })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d32fea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>\"get /api/v1/profile/30/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>\"patch /api/v1/profile/43/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>\"patch /api/v1/profile/48/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>\"patch /api/v1/profile/36/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>\"patch /api/v1/profile/43/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>\"get /api/v1/profile/48/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>\"get /api/v1/profile/1/ http/1.0\" 200 100\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>\"patch /api/v1/profile/39/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>\"patch /api/v1/profile/11/ http/1.0\" 200 105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>\"patch /api/v1/profile/2/ http/1.0\" 200 100\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170625 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                log\n",
       "datetime                                                           \n",
       "2022-08-10 00:29:00    \"get /api/v1/profile/30/ http/1.0\" 200 105\\n\n",
       "2022-08-10 00:29:00  \"patch /api/v1/profile/43/ http/1.0\" 200 105\\n\n",
       "2022-08-10 00:29:00  \"patch /api/v1/profile/48/ http/1.0\" 200 105\\n\n",
       "2022-08-10 00:29:00  \"patch /api/v1/profile/36/ http/1.0\" 200 105\\n\n",
       "2022-08-10 00:29:00  \"patch /api/v1/profile/43/ http/1.0\" 200 105\\n\n",
       "...                                                             ...\n",
       "2022-08-10 01:29:01    \"get /api/v1/profile/48/ http/1.0\" 200 105\\n\n",
       "2022-08-10 01:29:01     \"get /api/v1/profile/1/ http/1.0\" 200 100\\n\n",
       "2022-08-10 01:29:01  \"patch /api/v1/profile/39/ http/1.0\" 200 105\\n\n",
       "2022-08-10 01:29:01  \"patch /api/v1/profile/11/ http/1.0\" 200 105\\n\n",
       "2022-08-10 01:29:01   \"patch /api/v1/profile/2/ http/1.0\" 200 100\\n\n",
       "\n",
       "[170625 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_django = pd.DataFrame(data_list)\n",
    "df_django['log'] = df_django['log'].str.lower()\n",
    "df_django['datetime'] = pd.to_datetime(df_django['datetime'])\n",
    "df_django = df_django.set_index('datetime')\n",
    "df_django_original = df_django.copy(deep=True)\n",
    "df_django"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96bb92",
   "metadata": {},
   "source": [
    "### 2.1.2 count and summarize error logs in every 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66752d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_620242/1145327178.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df = df[error_word].groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>datetime</th>\n",
       "      <th>404</th>\n",
       "      <th>not found</th>\n",
       "      <th>internal server error</th>\n",
       "      <th>error</th>\n",
       "      <th>timed out</th>\n",
       "      <th>abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-10 00:29:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-10 00:29:20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-08-10 00:29:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-10 00:29:40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-08-10 00:29:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>2022-08-10 01:28:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>2022-08-10 01:28:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>2022-08-10 01:28:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>2022-08-10 01:29:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>2022-08-10 01:29:10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index            datetime  404  not found  internal server error  error  \\\n",
       "0        0 2022-08-10 00:29:10    0          0                      0      0   \n",
       "1        1 2022-08-10 00:29:20    1          2                      0      1   \n",
       "2        2 2022-08-10 00:29:30    0          0                      0      0   \n",
       "3        3 2022-08-10 00:29:40    0          2                      0      0   \n",
       "4        4 2022-08-10 00:29:50    0          0                      1      0   \n",
       "..     ...                 ...  ...        ...                    ...    ...   \n",
       "356    356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "357    357 2022-08-10 01:28:40    0          1                      0      2   \n",
       "358    358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "359    359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "360    360 2022-08-10 01:29:10    0          2                      0      0   \n",
       "\n",
       "     timed out  abnormal  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            2         0  \n",
       "..         ...       ...  \n",
       "356          0         0  \n",
       "357          0         0  \n",
       "358          0         0  \n",
       "359          1         0  \n",
       "360          0         0  \n",
       "\n",
       "[361 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_django = count_error_word(df_django, error_word)\n",
    "df_django_group_test = group_time(df_django)\n",
    "df_django_group_test\n",
    "\n",
    "df_django_group_train = set_train_data(df_django_group_test.copy(deep=True), error_word)\n",
    "df_django_group_train['abnormal'] = 0\n",
    "df_django_group_train = df_django_group_train.reset_index()\n",
    "df_django_group_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d31070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>404</th>\n",
       "      <th>not found</th>\n",
       "      <th>internal server error</th>\n",
       "      <th>error</th>\n",
       "      <th>timed out</th>\n",
       "      <th>abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2022-08-10 00:49:20</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2022-08-10 01:09:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2022-08-10 01:09:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2022-08-10 01:09:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2022-08-10 01:09:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2022-08-10 01:09:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-08-10 01:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-08-10 01:10:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  404  not found  internal server error  error  \\\n",
       "121 2022-08-10 00:49:20   50         50                      0      0   \n",
       "240 2022-08-10 01:09:10    0          0                      6     18   \n",
       "241 2022-08-10 01:09:20    0          0                     14     42   \n",
       "242 2022-08-10 01:09:30    0          0                     13     39   \n",
       "243 2022-08-10 01:09:40    0          0                      6     18   \n",
       "244 2022-08-10 01:09:50    0          0                     13     39   \n",
       "245 2022-08-10 01:10:00    0          0                     14     42   \n",
       "246 2022-08-10 01:10:10    0          0                     12     36   \n",
       "\n",
       "     timed out  abnormal  \n",
       "121          0       1.0  \n",
       "240          0       1.0  \n",
       "241          0       1.0  \n",
       "242          0       1.0  \n",
       "243          0       1.0  \n",
       "244          0       1.0  \n",
       "245          0       1.0  \n",
       "246          0       1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_django_group_test[df_django_group_test['abnormal'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f9010",
   "metadata": {},
   "source": [
    "### 2.1.3 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465d78f",
   "metadata": {},
   "source": [
    "#### Train isolation_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf914474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:10:58 INFO     isolation_forest\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.01}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:10:58 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:10:59 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:10:59 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:10:59 INFO                parameter_result {'contamination': 0.5}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'isolation_forest'\n",
    "model_details_django[model_name] = get_model_result(model_name, df_django_group_train, df_django_group_test, error_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382456a7",
   "metadata": {},
   "source": [
    "#### Train local_outilier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb87318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:11:00 INFO     local_outilier\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'local_outilier'\n",
    "model_details_django[model_name] = get_model_result(model_name, df_django_group_train, df_django_group_test, error_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891661cb",
   "metadata": {},
   "source": [
    "#### Train Elliptic_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c627a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:11:00 INFO     elliptic_envelope\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'contamination': 0.255}\n",
      "2022-08-18 16:11:00 INFO                parameter_result {'contamination': 0.5}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'elliptic_envelope'\n",
    "model_details_django[model_name] = get_model_result(model_name, df_django_group_train, df_django_group_test, error_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48d08da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>404</th>\n",
       "      <th>not found</th>\n",
       "      <th>internal server error</th>\n",
       "      <th>error</th>\n",
       "      <th>timed out</th>\n",
       "      <th>abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2022-08-10 00:49:20</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2022-08-10 01:09:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2022-08-10 01:09:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2022-08-10 01:09:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2022-08-10 01:09:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2022-08-10 01:09:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-08-10 01:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-08-10 01:10:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  404  not found  internal server error  error  \\\n",
       "121 2022-08-10 00:49:20   50         50                      0      0   \n",
       "240 2022-08-10 01:09:10    0          0                      6     18   \n",
       "241 2022-08-10 01:09:20    0          0                     14     42   \n",
       "242 2022-08-10 01:09:30    0          0                     13     39   \n",
       "243 2022-08-10 01:09:40    0          0                      6     18   \n",
       "244 2022-08-10 01:09:50    0          0                     13     39   \n",
       "245 2022-08-10 01:10:00    0          0                     14     42   \n",
       "246 2022-08-10 01:10:10    0          0                     12     36   \n",
       "\n",
       "     timed out  abnormal  \n",
       "121          0       1.0  \n",
       "240          0       1.0  \n",
       "241          0       1.0  \n",
       "242          0       1.0  \n",
       "243          0       1.0  \n",
       "244          0       1.0  \n",
       "245          0       1.0  \n",
       "246          0       1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_django_group_test[df_django_group_test['abnormal'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975da0c",
   "metadata": {},
   "source": [
    "### 2.1.4 Max F1 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de33f115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : nan, F1 of each hyper: [nan, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_django['isolation_forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07159452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 1.0, F1 of each hyper: [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_django['local_outilier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df9c735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 1.0, F1 of each hyper: [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_django['elliptic_envelope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a44d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter': {'contamination': 0.01},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'contamination': 0.255},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'contamination': 0.5},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details_django['elliptic_envelope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9628cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter': {'n_neighbors': 1, 'novelty': True},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'n_neighbors': 50, 'novelty': True},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'n_neighbors': 100, 'novelty': True},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'n_neighbors': 150, 'novelty': True},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]},\n",
       " {'parameter': {'n_neighbors': 200, 'novelty': True},\n",
       "  'metric_result': {'confusion_matrix': array([[353,   0],\n",
       "          [  0,   8]]),\n",
       "   'TN': 353,\n",
       "   'FP': 0,\n",
       "   'FN': 0,\n",
       "   'TP': 8,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'specificity': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'F1': '1.0000'},\n",
       "  'predict':                datetime  404  not found  internal server error  error  \\\n",
       "  0   2022-08-10 00:29:10    0          0                      0      0   \n",
       "  1   2022-08-10 00:29:20    0          0                      0      0   \n",
       "  2   2022-08-10 00:29:30    0          0                      0      0   \n",
       "  3   2022-08-10 00:29:40    0          0                      0      0   \n",
       "  4   2022-08-10 00:29:50    0          0                      0      0   \n",
       "  ..                  ...  ...        ...                    ...    ...   \n",
       "  356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "  357 2022-08-10 01:28:40    0          0                      0      0   \n",
       "  358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "  359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "  360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "  \n",
       "       timed out  abnormal  predict  \n",
       "  0            0       0.0        0  \n",
       "  1            0       0.0        0  \n",
       "  2            0       0.0        0  \n",
       "  3            0       0.0        0  \n",
       "  4            0       0.0        0  \n",
       "  ..         ...       ...      ...  \n",
       "  356          0       0.0        0  \n",
       "  357          0       0.0        0  \n",
       "  358          0       0.0        0  \n",
       "  359          0       0.0        0  \n",
       "  360          0       0.0        0  \n",
       "  \n",
       "  [361 rows x 8 columns]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details_django['local_outilier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15a6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_dataset(model_details_django['local_outilier'][0])  # uncomment to see visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d1fed",
   "metadata": {},
   "source": [
    "## 2.2. process Nginx logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f099a46",
   "metadata": {},
   "source": [
    "### 2.2.1  parse logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253955d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data  = open('input/nginx.log', 'r')\n",
    "data_list = []\n",
    "last_date = datetime.strptime('09/Aug/2022:23:50:16', '%d/%b/%Y:%H:%M:%S')\n",
    "for i, line in enumerate(log_data):\n",
    "    date_str = line[45:65]\n",
    "    try:\n",
    "        datetime_data = datetime.strptime(date_str, '%d/%b/%Y:%H:%M:%S')\n",
    "        last_date = datetime_data\n",
    "        log = text[72:]\n",
    "    except Exception as e:\n",
    "        datetime_data = last_date\n",
    "        log = line[29:]\n",
    "\n",
    "    data_list.append({\n",
    "        'datetime': datetime_data, \n",
    "        'log': log,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283d35f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 00:29:00</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10 01:29:01</th>\n",
       "      <td>172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   log\n",
       "datetime                                                              \n",
       "2022-08-10 00:29:00  172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"p...\n",
       "2022-08-10 00:29:00  172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"p...\n",
       "2022-08-10 00:29:00  172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...\n",
       "2022-08-10 00:29:00  172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...\n",
       "2022-08-10 00:29:00  172.22.0.1 - - [10/aug/2022:00:29:00 +0000] \"g...\n",
       "...                                                                ...\n",
       "2022-08-10 01:29:01  172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"g...\n",
       "2022-08-10 01:29:01  172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"g...\n",
       "2022-08-10 01:29:01  172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...\n",
       "2022-08-10 01:29:01  172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...\n",
       "2022-08-10 01:29:01  172.22.0.1 - - [10/aug/2022:01:29:01 +0000] \"p...\n",
       "\n",
       "[168989 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nginx = pd.DataFrame(data_list)\n",
    "df_nginx['log'] = df_nginx['log'].str.lower()\n",
    "df_nginx = df_nginx.set_index('datetime')\n",
    "df_nginx_original = df_nginx.copy(deep=True)\n",
    "df_nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde14ea",
   "metadata": {},
   "source": [
    "### 2.2.2 count and summarize error logs in every 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85c5a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_620242/1145327178.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df = df[error_word].groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>datetime</th>\n",
       "      <th>404</th>\n",
       "      <th>not found</th>\n",
       "      <th>internal server error</th>\n",
       "      <th>error</th>\n",
       "      <th>timed out</th>\n",
       "      <th>abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-10 00:29:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-10 00:29:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-08-10 00:29:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-10 00:29:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-08-10 00:29:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>2022-08-10 01:28:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>2022-08-10 01:28:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>2022-08-10 01:28:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>2022-08-10 01:29:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>2022-08-10 01:29:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index            datetime  404  not found  internal server error  error  \\\n",
       "0        0 2022-08-10 00:29:10    1          0                      0      0   \n",
       "1        1 2022-08-10 00:29:20    0          0                      1      0   \n",
       "2        2 2022-08-10 00:29:30    0          0                      0      0   \n",
       "3        3 2022-08-10 00:29:40    0          1                      2      2   \n",
       "4        4 2022-08-10 00:29:50    0          0                      0      0   \n",
       "..     ...                 ...  ...        ...                    ...    ...   \n",
       "356    356 2022-08-10 01:28:30    0          0                      0      0   \n",
       "357    357 2022-08-10 01:28:40    0          1                      2      1   \n",
       "358    358 2022-08-10 01:28:50    0          0                      0      0   \n",
       "359    359 2022-08-10 01:29:00    0          0                      0      0   \n",
       "360    360 2022-08-10 01:29:10    0          0                      0      0   \n",
       "\n",
       "     timed out  abnormal  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "..         ...       ...  \n",
       "356          0         0  \n",
       "357          0         0  \n",
       "358          1         0  \n",
       "359          1         0  \n",
       "360          0         0  \n",
       "\n",
       "[361 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nginx = count_error_word(df_nginx, error_word)\n",
    "df_nginx_group_test = group_time(df_nginx)\n",
    "df_nginx_group_test\n",
    "\n",
    "df_nginx_group_train = set_train_data(df_nginx_group_test.copy(deep=True), error_word)\n",
    "df_nginx_group_train['abnormal'] = 0\n",
    "df_nginx_group_train = df_nginx_group_train.reset_index()\n",
    "df_nginx_group_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8626597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>404</th>\n",
       "      <th>not found</th>\n",
       "      <th>internal server error</th>\n",
       "      <th>error</th>\n",
       "      <th>timed out</th>\n",
       "      <th>abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2022-08-10 00:49:20</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2022-08-10 01:09:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2022-08-10 01:09:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2022-08-10 01:09:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2022-08-10 01:09:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2022-08-10 01:09:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2022-08-10 01:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2022-08-10 01:10:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2022-08-10 01:20:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2022-08-10 01:21:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2022-08-10 01:23:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  404  not found  internal server error  error  \\\n",
       "121 2022-08-10 00:49:20   50          0                      0      0   \n",
       "240 2022-08-10 01:09:10    0          0                      0      6   \n",
       "241 2022-08-10 01:09:20    0          0                      0     14   \n",
       "242 2022-08-10 01:09:30    0          0                      0     13   \n",
       "243 2022-08-10 01:09:40    0          0                      0      6   \n",
       "244 2022-08-10 01:09:50    0          0                      0     13   \n",
       "245 2022-08-10 01:10:00    0          0                      0     14   \n",
       "246 2022-08-10 01:10:10    0          0                      0     12   \n",
       "309 2022-08-10 01:20:40    0          0                      0     10   \n",
       "316 2022-08-10 01:21:50    0          0                      0     10   \n",
       "323 2022-08-10 01:23:00    0          0                      0     10   \n",
       "\n",
       "     timed out  abnormal  \n",
       "121          0       1.0  \n",
       "240          0       1.0  \n",
       "241          0       1.0  \n",
       "242          0       1.0  \n",
       "243          0       1.0  \n",
       "244          0       1.0  \n",
       "245          0       1.0  \n",
       "246          0       1.0  \n",
       "309         10       1.0  \n",
       "316         10       1.0  \n",
       "323         10       1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nginx_group_test[df_nginx_group_test['abnormal'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121dd34",
   "metadata": {},
   "source": [
    "### 2.2.3 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29de66",
   "metadata": {},
   "source": [
    "#### Train isolation_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdea0dda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:11:05 INFO     isolation_forest\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.01}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:11:05 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'contamination': 0.5}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'isolation_forest'\n",
    "model_details_nginx[model_name] = get_model_result(model_name, df_nginx_group_train, df_nginx_group_test, error_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93948460",
   "metadata": {},
   "source": [
    "#### Train local_outilier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45253629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:11:06 INFO     local_outilier\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'local_outilier'\n",
    "model_details_nginx[model_name] = get_model_result(model_name, df_nginx_group_train, df_nginx_group_test, error_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce1eb5",
   "metadata": {},
   "source": [
    "#### Train elliptic_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a6a9d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 16:11:06 INFO     elliptic_envelope\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'contamination': 0.255}\n",
      "2022-08-18 16:11:06 INFO                parameter_result {'contamination': 0.5}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'elliptic_envelope'\n",
    "model_details_nginx[model_name] = get_model_result(model_name, df_nginx_group_train, df_nginx_group_test, error_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96ab79",
   "metadata": {},
   "source": [
    "### 2.2.4 Find Max F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c32174f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : nan, F1 of each hyper: [nan, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286, 0.5333, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_nginx['isolation_forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8ccb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 1.0, F1 of each hyper: [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_nginx['local_outilier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73bf03de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 1.0, F1 of each hyper: [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_nginx['elliptic_envelope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b399f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameter': {'contamination': 0.44555555555555554},\n",
       " 'metric_result': {'confusion_matrix': array([[350,   0],\n",
       "         [  7,   4]]),\n",
       "  'TN': 350,\n",
       "  'FP': 0,\n",
       "  'FN': 7,\n",
       "  'TP': 4,\n",
       "  'precision': 1.0,\n",
       "  'recall': 0.36363636363636365,\n",
       "  'specificity': 1.0,\n",
       "  'accuracy': 0.9806094182825484,\n",
       "  'F1': '0.5333'},\n",
       " 'predict':                datetime  404  not found  internal server error  error  \\\n",
       " 0   2022-08-10 00:29:10    0          0                      0      0   \n",
       " 1   2022-08-10 00:29:20    0          0                      0      0   \n",
       " 2   2022-08-10 00:29:30    0          0                      0      0   \n",
       " 3   2022-08-10 00:29:40    0          0                      0      0   \n",
       " 4   2022-08-10 00:29:50    0          0                      0      0   \n",
       " ..                  ...  ...        ...                    ...    ...   \n",
       " 356 2022-08-10 01:28:30    0          0                      0      0   \n",
       " 357 2022-08-10 01:28:40    0          0                      0      0   \n",
       " 358 2022-08-10 01:28:50    0          0                      0      0   \n",
       " 359 2022-08-10 01:29:00    0          0                      0      0   \n",
       " 360 2022-08-10 01:29:10    0          0                      0      0   \n",
       " \n",
       "      timed out  abnormal  predict  \n",
       " 0            0       0.0        0  \n",
       " 1            0       0.0        0  \n",
       " 2            0       0.0        0  \n",
       " 3            0       0.0        0  \n",
       " 4            0       0.0        0  \n",
       " ..         ...       ...      ...  \n",
       " 356          0       0.0        0  \n",
       " 357          0       0.0        0  \n",
       " 358          0       0.0        0  \n",
       " 359          0       0.0        0  \n",
       " 360          0       0.0        0  \n",
       " \n",
       " [361 rows x 8 columns]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details_nginx['isolation_forest'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1618b00",
   "metadata": {},
   "source": [
    "## 2.3 Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4beb35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/model_details_count_django.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_details_django, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67f64eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/model_details_count_nginx.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_details_nginx, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909802d",
   "metadata": {},
   "source": [
    "# 3. Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e62444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details_hash = {\n",
    "    'django': {},\n",
    "    'nginx': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869aeb5",
   "metadata": {},
   "source": [
    "## 3.1 Define train hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffb324d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hash(df_data, df_data_group_test):\n",
    "    df_2 = df_data.reset_index()\n",
    "    model_detail = {}\n",
    "    for i in range(7,11):\n",
    "        print(i)\n",
    "        vectorizer = HashingVectorizer(n_features=2**i)\n",
    "        vectorizer = vectorizer.fit(df_data['log'])\n",
    "        spar_data = vectorizer.transform(df_data['log'])\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(spar_data.toarray())\n",
    "        df_result = df_2.join(df)\n",
    "        df_result = df_result.drop(columns=['log']).set_index('datetime')\n",
    "        df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
    "        select_column = df_result_group.columns.tolist()\n",
    "\n",
    "        df_train = df_result_group.reset_index()\n",
    "        df_train.loc[df_data_group_test['abnormal'] > 0, 'abnormal'] = 1\n",
    "        df_train['abnormal'] = df_train['abnormal'].fillna(0)\n",
    "\n",
    "        if i not in model_detail:\n",
    "            model_detail[i] = {}\n",
    "\n",
    "        model_name = 'isolation_forest'\n",
    "        model_detail[i][model_name] = get_model_result(model_name, df_train, df_train, select_column)\n",
    "\n",
    "        model_name = 'local_outilier'\n",
    "        model_detail[i][model_name] = get_model_result(model_name, df_train, df_train, select_column)\n",
    "\n",
    "        model_name = 'elliptic_envelope'\n",
    "        model_detail[i][model_name] = get_model_result(model_name, df_train, df_train, select_column)\n",
    "\n",
    "        print( print_F1(model_detail[i]['isolation_forest']) )\n",
    "        print( print_F1(model_detail[i]['local_outilier']) )\n",
    "        print( print_F1(model_detail[i]['elliptic_envelope']) ) \n",
    "        \n",
    "    return model_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003a814",
   "metadata": {},
   "source": [
    "## 3.2 Train Django logs with Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6453aa4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:24:26 INFO     isolation_forest\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:24:26 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:24:27 INFO     local_outilier\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:24:27 INFO     elliptic_envelope\n",
      "2022-08-18 16:24:27 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:24:28 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:24:29 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.5, 0.3137, 0.2254, 0.1778, 0.1455, 0.1231, 0.1074, 0.0947, 0.0851]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0.6667, 0.2, 0.1311, 0.1356]\n",
      "None\n",
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.16, 0.0851]\n",
      "None\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:24:31 INFO     isolation_forest\n",
      "2022-08-18 16:24:31 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:24:31 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:24:31 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:24:31 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:24:32 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:24:33 INFO     local_outilier\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:24:33 INFO     elliptic_envelope\n",
      "2022-08-18 16:24:33 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:24:35 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:24:39 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.5, 0.3137, 0.2254, 0.1778, 0.1455, 0.1231, 0.1074, 0.0947, 0.0851]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0.6667, 0.2051, 0.1311, 0.1356]\n",
      "None\n",
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.16, 0.0847]\n",
      "None\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:24:47 INFO     isolation_forest\n",
      "2022-08-18 16:24:47 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:24:47 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:24:47 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:24:48 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:24:48 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:24:48 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:24:48 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:24:49 INFO     local_outilier\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:24:49 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:24:50 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:24:50 INFO     elliptic_envelope\n",
      "2022-08-18 16:24:50 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:24:59 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:25:08 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.5, 0.3137, 0.2254, 0.1778, 0.1455, 0.1231, 0.1074, 0.0947, 0.0851]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0.6667, 0.2025, 0.1311, 0.1356]\n",
      "None\n",
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.16, 0.0851]\n",
      "None\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:25:28 INFO     isolation_forest\n",
      "2022-08-18 16:25:28 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:25:28 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:25:28 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:25:29 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:25:29 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:25:29 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:25:30 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:25:30 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:25:30 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:25:30 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:25:31 INFO     local_outilier\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:25:31 INFO     elliptic_envelope\n",
      "2022-08-18 16:25:31 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:25:52 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:26:12 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.5, 0.3137, 0.2254, 0.1778, 0.1455, 0.1231, 0.1074, 0.0947, 0.0851]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0.6667, 0.2025, 0.1311, 0.1356]\n",
      "None\n",
      "     F1 max : 0.6667, F1 of each hyper: [0.6667, 0.16, 0.0847]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_details_hash['django'] = train_hash(df_django_original, df_django_group_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f124255",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/model_details_hash_django.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_details_hash['django'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666a546",
   "metadata": {},
   "source": [
    "## 3.3 Train Django logs with Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caeb69c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:11:17 INFO     isolation_forest\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:11:17 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:11:18 INFO     local_outilier\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:11:18 INFO     elliptic_envelope\n",
      "2022-08-18 16:11:18 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:11:20 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:11:23 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.4, F1 of each hyper: [0.4, 0.2286, 0.1481, 0.1622, 0.1935, 0.1593, 0.0902, 0.0921, 0.0698, 0.1152]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0, 0, 0, 0]\n",
      "None\n",
      "     F1 max : 0.1047, F1 of each hyper: [0, 0.0583, 0.1047]\n",
      "None\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:11:27 INFO     isolation_forest\n",
      "2022-08-18 16:11:27 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:11:28 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:11:28 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:11:29 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:11:31 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:11:31 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:11:31 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:11:32 INFO     local_outilier\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:11:32 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:11:33 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:11:33 INFO     elliptic_envelope\n",
      "2022-08-18 16:11:33 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:11:37 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:11:44 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.2857, 0.1852, 0.1622, 0.1505, 0.1593, 0.1353, 0.0526, 0.0814, 0.0838]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0, 0, 0, 0]\n",
      "None\n",
      "     F1 max : 0.2136, F1 of each hyper: [0, 0.2136, 0.1146]\n",
      "None\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:11:50 INFO     isolation_forest\n",
      "2022-08-18 16:11:50 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:11:50 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:11:50 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:11:51 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:11:52 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:11:52 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:11:53 INFO     local_outilier\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:11:53 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:11:54 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:11:54 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:11:54 INFO     elliptic_envelope\n",
      "2022-08-18 16:11:54 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:12:04 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:12:15 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.5143, 0.2593, 0.2703, 0.2366, 0.177, 0.1654, 0.1447, 0.1279, 0.1152]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0, 0, 0, 0]\n",
      "None\n",
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.2136, 0.1152]\n",
      "None\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458326/3508988229.py:14: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  df_result_group = df_result.groupby(pd.Grouper(freq='10S', base=0, label='right')).sum()\n",
      "2022-08-18 16:12:33 INFO     isolation_forest\n",
      "2022-08-18 16:12:33 INFO                parameter_result {'contamination': 0.01}\n",
      "2022-08-18 16:12:33 INFO                parameter_result {'contamination': 0.06444444444444444}\n",
      "2022-08-18 16:12:34 INFO                parameter_result {'contamination': 0.11888888888888888}\n",
      "2022-08-18 16:12:34 INFO                parameter_result {'contamination': 0.17333333333333334}\n",
      "2022-08-18 16:12:35 INFO                parameter_result {'contamination': 0.22777777777777777}\n",
      "2022-08-18 16:12:35 INFO                parameter_result {'contamination': 0.2822222222222222}\n",
      "2022-08-18 16:12:37 INFO                parameter_result {'contamination': 0.33666666666666667}\n",
      "2022-08-18 16:12:39 INFO                parameter_result {'contamination': 0.3911111111111111}\n",
      "2022-08-18 16:12:40 INFO                parameter_result {'contamination': 0.44555555555555554}\n",
      "2022-08-18 16:12:40 INFO                parameter_result {'contamination': 0.5}\n",
      "2022-08-18 16:12:40 INFO     local_outilier\n",
      "2022-08-18 16:12:40 INFO                parameter_result {'n_neighbors': 1, 'novelty': True}\n",
      "/tmp/ipykernel_458326/2622401338.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "2022-08-18 16:12:41 INFO                parameter_result {'n_neighbors': 50, 'novelty': True}\n",
      "2022-08-18 16:12:41 INFO                parameter_result {'n_neighbors': 100, 'novelty': True}\n",
      "2022-08-18 16:12:42 INFO                parameter_result {'n_neighbors': 150, 'novelty': True}\n",
      "2022-08-18 16:12:42 INFO                parameter_result {'n_neighbors': 200, 'novelty': True}\n",
      "2022-08-18 16:12:43 INFO     elliptic_envelope\n",
      "2022-08-18 16:12:43 INFO                parameter_result {'contamination': 0.01}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:13:10 INFO                parameter_result {'contamination': 0.255}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "2022-08-18 16:13:31 INFO                parameter_result {'contamination': 0.5}\n",
      "/home/patcharapon/miniconda3/envs/facebook-kats/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:738: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.4571, 0.2963, 0.2703, 0.2366, 0.1947, 0.1654, 0.1447, 0.1279, 0.1152]\n",
      "None\n",
      "     F1 max : nan, F1 of each hyper: [nan, 0, 0, 0, 0]\n",
      "None\n",
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.2136, 0.1152]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_details_hash['nginx'] = train_hash(df_nginx_original, df_nginx_group_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e6b1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('count/model_details_hash_nginx.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_details_hash['nginx'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2153c6",
   "metadata": {},
   "source": [
    "## 3.4  Find Max F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0484ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.5143, 0.2593, 0.2703, 0.2366, 0.177, 0.1654, 0.1447, 0.1279, 0.1152]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_hash_nginx[9]['isolation_forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4084e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F1 max : 0.5333, F1 of each hyper: [0.5333, 0.2136, 0.1152]\n"
     ]
    }
   ],
   "source": [
    "print_F1(model_details_hash_nginx[9]['elliptic_envelope'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc643b",
   "metadata": {},
   "source": [
    "## Example Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a9ddbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameter': {'contamination': 0.01},\n",
       " 'metric_result': {'confusion_matrix': array([[350,   0],\n",
       "         [  7,   4]]),\n",
       "  'TN': 350,\n",
       "  'FP': 0,\n",
       "  'FN': 7,\n",
       "  'TP': 4,\n",
       "  'precision': 1.0,\n",
       "  'recall': 0.36363636363636365,\n",
       "  'specificity': 1.0,\n",
       "  'accuracy': 0.9806094182825484,\n",
       "  'F1': '0.5333'},\n",
       " 'predict':                datetime           0    1    2    3    4    5    6          7  \\\n",
       " 0   2022-08-10 00:29:10   11.202614  0.0  0.0  0.0  0.0  0.0  0.0   1.800950   \n",
       " 1   2022-08-10 00:29:20    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   2.683282   \n",
       " 2   2022-08-10 00:29:30    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   1.747230   \n",
       " 3   2022-08-10 00:29:40    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  13.816438   \n",
       " 4   2022-08-10 00:29:50    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   2.683282   \n",
       " ..                  ...         ...  ...  ...  ...  ...  ...  ...        ...   \n",
       " 356 2022-08-10 01:28:30  104.525431  0.0  0.0  0.0  0.0  0.0  0.0   3.785291   \n",
       " 357 2022-08-10 01:28:40   76.912735  0.0  0.0  0.0  0.0  0.0  0.0  11.977234   \n",
       " 358 2022-08-10 01:28:50  105.943108  0.0  0.0  0.0  0.0  0.0  0.0   2.771609   \n",
       " 359 2022-08-10 01:29:00   88.381806  0.0  0.0  0.0  0.0  0.0  0.0   3.198011   \n",
       " 360 2022-08-10 01:29:10   13.763664  0.0  0.0  0.0  0.0  0.0  0.0   0.447214   \n",
       " \n",
       "        8  ...  504  505  506        507        508  509  510  511  abnormal  \\\n",
       " 0    0.0  ...  0.0  0.0  0.0  -1.320829  87.578425  0.0  0.0  0.0       0.0   \n",
       " 1    0.0  ...  0.0  0.0  0.0  -2.225662  89.443173  0.0  0.0  0.0       0.0   \n",
       " 2    0.0  ...  0.0  0.0  0.0  -0.894427  87.681370  0.0  0.0  0.0       0.0   \n",
       " 3    0.0  ...  0.0  0.0  0.0  -2.012461  90.466850  0.0  0.0  0.0       0.0   \n",
       " 4    0.0  ...  0.0  0.0  0.0 -13.669309  92.489718  0.0  0.0  0.0       0.0   \n",
       " ..   ...  ...  ...  ...  ...        ...        ...  ...  ...  ...       ...   \n",
       " 356  0.0  ...  0.0  0.0  0.0  -2.540255  84.273945  0.0  0.0  0.0       0.0   \n",
       " 357  0.0  ...  0.0  0.0  0.0  -1.918806  60.109957  0.0  0.0  0.0       0.0   \n",
       " 358  0.0  ...  0.0  0.0  0.0 -11.710870  86.739934  0.0  0.0  0.0       0.0   \n",
       " 359  0.0  ...  0.0  0.0  0.0  -1.918806  72.670118  0.0  0.0  0.0       0.0   \n",
       " 360  0.0  ...  0.0  0.0  0.0  -0.660414  10.202664  0.0  0.0  0.0       0.0   \n",
       " \n",
       "      predict  \n",
       " 0          0  \n",
       " 1          0  \n",
       " 2          0  \n",
       " 3          0  \n",
       " 4          0  \n",
       " ..       ...  \n",
       " 356        0  \n",
       " 357        0  \n",
       " 358        0  \n",
       " 359        0  \n",
       " 360        0  \n",
       " \n",
       " [361 rows x 515 columns]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details_hash_nginx[9]['isolation_forest'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9889ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameter': {'contamination': 0.01},\n",
       " 'metric_result': {'confusion_matrix': array([[350,   0],\n",
       "         [  7,   4]]),\n",
       "  'TN': 350,\n",
       "  'FP': 0,\n",
       "  'FN': 7,\n",
       "  'TP': 4,\n",
       "  'precision': 1.0,\n",
       "  'recall': 0.36363636363636365,\n",
       "  'specificity': 1.0,\n",
       "  'accuracy': 0.9806094182825484,\n",
       "  'F1': '0.5333'},\n",
       " 'predict':                datetime           0    1    2    3    4    5    6          7  \\\n",
       " 0   2022-08-10 00:29:10   11.202614  0.0  0.0  0.0  0.0  0.0  0.0   1.800950   \n",
       " 1   2022-08-10 00:29:20    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   2.683282   \n",
       " 2   2022-08-10 00:29:30    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   1.747230   \n",
       " 3   2022-08-10 00:29:40    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  13.816438   \n",
       " 4   2022-08-10 00:29:50    0.000000  0.0  0.0  0.0  0.0  0.0  0.0   2.683282   \n",
       " ..                  ...         ...  ...  ...  ...  ...  ...  ...        ...   \n",
       " 356 2022-08-10 01:28:30  104.525431  0.0  0.0  0.0  0.0  0.0  0.0   3.785291   \n",
       " 357 2022-08-10 01:28:40   76.912735  0.0  0.0  0.0  0.0  0.0  0.0  11.977234   \n",
       " 358 2022-08-10 01:28:50  105.943108  0.0  0.0  0.0  0.0  0.0  0.0   2.771609   \n",
       " 359 2022-08-10 01:29:00   88.381806  0.0  0.0  0.0  0.0  0.0  0.0   3.198011   \n",
       " 360 2022-08-10 01:29:10   13.763664  0.0  0.0  0.0  0.0  0.0  0.0   0.447214   \n",
       " \n",
       "        8  ...  504  505  506        507        508  509  510  511  abnormal  \\\n",
       " 0    0.0  ...  0.0  0.0  0.0  -1.320829  87.578425  0.0  0.0  0.0       0.0   \n",
       " 1    0.0  ...  0.0  0.0  0.0  -2.225662  89.443173  0.0  0.0  0.0       0.0   \n",
       " 2    0.0  ...  0.0  0.0  0.0  -0.894427  87.681370  0.0  0.0  0.0       0.0   \n",
       " 3    0.0  ...  0.0  0.0  0.0  -2.012461  90.466850  0.0  0.0  0.0       0.0   \n",
       " 4    0.0  ...  0.0  0.0  0.0 -13.669309  92.489718  0.0  0.0  0.0       0.0   \n",
       " ..   ...  ...  ...  ...  ...        ...        ...  ...  ...  ...       ...   \n",
       " 356  0.0  ...  0.0  0.0  0.0  -2.540255  84.273945  0.0  0.0  0.0       0.0   \n",
       " 357  0.0  ...  0.0  0.0  0.0  -1.918806  60.109957  0.0  0.0  0.0       0.0   \n",
       " 358  0.0  ...  0.0  0.0  0.0 -11.710870  86.739934  0.0  0.0  0.0       0.0   \n",
       " 359  0.0  ...  0.0  0.0  0.0  -1.918806  72.670118  0.0  0.0  0.0       0.0   \n",
       " 360  0.0  ...  0.0  0.0  0.0  -0.660414  10.202664  0.0  0.0  0.0       0.0   \n",
       " \n",
       "      predict  \n",
       " 0          0  \n",
       " 1          0  \n",
       " 2          0  \n",
       " 3          0  \n",
       " 4          0  \n",
       " ..       ...  \n",
       " 356        0  \n",
       " 357        0  \n",
       " 358        0  \n",
       " 359        0  \n",
       " 360        0  \n",
       " \n",
       " [361 rows x 515 columns]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details_hash_nginx[9]['elliptic_envelope'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
